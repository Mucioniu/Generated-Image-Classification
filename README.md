# Generated Image Classification

## Overview
This is a deep image hallucination classification in which various deep classification models were trained on a data set containing images generated by deep generative models.

## Key Features

1. Data Loading and Preprocessing
 - Libraries: Utilizes TensorFlow, Keras, OpenCV, NumPy, and Pandas for data handling and model training.
 - Data Preparation:
   - Images are loaded using OpenCV and labels extracted from a CSV file.
   - Data is split into training and validation sets with one-hot encoded labels.
   - Images are normalized to a [0.0, 1.0] range to enhance training efficiency.

2. Model Compilation and Training
 - Optimizers: Models are compiled using the Adam and SGD optimizers with a categorical cross-entropy loss function.
 - Data Augmentation: An ImageDataGenerator is used for data augmentation, including random rotations, shifts, and flips.
 - Learning Rate Schedule: Implements a learning rate schedule to improve convergence during training.
 - Early Stopping: Utilizes early stopping to prevent overfitting and save the best-performing models.

3. Model Architectures | Convolutional Neural Networks (CNNs)
 - Simple CNN:
   - Architecture: Two convolutional layers, max-pooling, dropout, flattening, and dense layers.
   - Results: Achieved a validation accuracy of 62.3% after training.
 - Mini MobileNet:
   - Architecture: Depthwise separable convolutions, global average pooling, and dense layers.
   - Results: Achieved a validation accuracy of 72.7% after training.
 - DenseNet Variants:
   - DenseNet 121 & 201: Implemented with dropout and weight decay variations.
   - Results: DenseNet 121 reached a validation accuracy of 83.45%, while DenseNet 201 achieved 81.15%.

## Final Results
The following table summarizes the final results of various models tested over 150 epochs with early stopping:

| **Model**                    | **Epochs** | **Training Accuracy** | **Training Loss** | **Validation Accuracy** | **Validation Loss** |
|------------------------------|------------|-----------------------|-------------------|-------------------------|---------------------|
| Simple CNN                   | 37         | 50.21%                | 1.6906            | 62.30%                  | 1.2943              |
| Mini MobileNet               | 74         | 81.92%                | 0.5563            | 72.70%                  | 0.9194              |
| DenseNet 121                 | 85         | 94.20%                | 0.2699            | 83.45%                  | 0.6294              |
| DenseNet 121 (Dropout/Decay) | 66         | 93.57%                | 1.0912            | 81.80%                  | 1.6204              |
| DenseNet 201                 | 63         | 94.78%                | 0.2574            | 81.15%                  | 0.8583              |
| DenseNet 201 (Dropout/Decay) | 54         | 78.46%                | 2.5252            | 73.35%                  | 3.8865              |

